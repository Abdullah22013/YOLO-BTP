{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290be4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2bcc838",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 416\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-5 # Lower LR for a more complex model\n",
    "EPOCHS = 50\n",
    "NUM_CLASSES = 11\n",
    "CONFIDENCE_THRESHOLD = 0.6\n",
    "IOU_THRESHOLD = 0.5\n",
    "ANCHORS = [\n",
    "    [(116, 90), (156, 198), (373, 326)],  # Scale 1 (13x13) for large objects\n",
    "    [(30, 61), (62, 45), (59, 119)],      # Scale 2 (26x26) for medium objects\n",
    "    [(10, 13), (16, 30), (33, 23)],        # Scale 3 (52x52) for small objects\n",
    "]\n",
    "S = [IMG_SIZE // 32, IMG_SIZE // 16, IMG_SIZE // 8] # Strides, Grid sizes: [13, 26, 52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f5e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_bn=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=not use_bn, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
    "        self.leaky = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.leaky(self.bn(self.conv(x)))\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, num_repeats=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_repeats):\n",
    "            self.layers += [\n",
    "                nn.Sequential(\n",
    "                    CNNBlock(channels, channels // 2, kernel_size=1),\n",
    "                    CNNBlock(channels // 2, channels, kernel_size=3, padding=1),\n",
    "                )\n",
    "            ]\n",
    "        self.num_repeats = num_repeats\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = x + layer(x)\n",
    "        return x\n",
    "\n",
    "class PredictionHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, anchors):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "        self.num_anchors = len(anchors)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            CNNBlock(in_channels, in_channels * 2, kernel_size=3, padding=1),\n",
    "            CNNBlock(in_channels * 2, (self.num_anchors * (5 + num_classes)), use_bn=False, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape the output to [Batch, Num_Anchors, Grid_S, Grid_S, 5 + Num_Classes]\n",
    "        out = self.head(x)\n",
    "        out = out.view(x.shape[0], self.num_anchors, 5 + self.num_classes, x.shape[2], x.shape[3])\n",
    "        out = out.permute(0, 1, 3, 4, 2)\n",
    "        return out\n",
    "\n",
    "class Darknet53(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.layers = nn.ModuleList([\n",
    "            CNNBlock(in_channels, 32, kernel_size=3, padding=1),\n",
    "            CNNBlock(32, 64, kernel_size=3, padding=1, stride=2),\n",
    "            ResidualBlock(64, num_repeats=1),\n",
    "            CNNBlock(64, 128, kernel_size=3, padding=1, stride=2),\n",
    "            ResidualBlock(128, num_repeats=2),\n",
    "            CNNBlock(128, 256, kernel_size=3, padding=1, stride=2),\n",
    "            ResidualBlock(256, num_repeats=8), # -> Route 1\n",
    "            CNNBlock(256, 512, kernel_size=3, padding=1, stride=2),\n",
    "            ResidualBlock(512, num_repeats=8), # -> Route 2\n",
    "            CNNBlock(512, 1024, kernel_size=3, padding=1, stride=2),\n",
    "            ResidualBlock(1024, num_repeats=4),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            # The routes are the outputs of the last three residual blocks\n",
    "            if i in [6, 8]:\n",
    "                outputs.append(x)\n",
    "        outputs.append(x)\n",
    "        return outputs[0], outputs[1], outputs[2] # 52x52, 26x26, 13x13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf0c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class YOLOv3(nn.Module):\n",
    "#     def __init__(self, in_channels=1, num_classes=11):\n",
    "#         super().__init__()\n",
    "#         self.num_classes = num_classes\n",
    "#         self.in_channels = in_channels\n",
    "#         self.backbone = Darknet53(in_channels=in_channels)\n",
    "        \n",
    "#         # Prediction Heads for each scale\n",
    "#         self.head1 = PredictionHead(1024, num_classes, ANCHORS[0]) # Large scale\n",
    "#         self.head2 = PredictionHead(512, num_classes, ANCHORS[1])  # Medium scale\n",
    "#         self.head3 = PredictionHead(256, num_classes, ANCHORS[2])  # Small scale\n",
    "\n",
    "#         self.conv1 = CNNBlock(1024, 512, kernel_size=1)\n",
    "#         self.conv2 = CNNBlock(512, 256, kernel_size=1)\n",
    "#         self.upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         route3, route2, route1 = self.backbone(x) # small, medium, large routes\n",
    "        \n",
    "#         # Scale 1 prediction (large objects)\n",
    "#         out1 = self.head1(route1)\n",
    "        \n",
    "#         # Scale 2 prediction (medium objects)\n",
    "#         x = self.conv1(route1)\n",
    "#         x = self.upsample(x)\n",
    "#         x = torch.cat([x, route2], dim=1)\n",
    "#         out2 = self.head2(x)\n",
    "\n",
    "#         # Scale 3 prediction (small objects)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.upsample(x)\n",
    "#         x = torch.cat([x, route3], dim=1)\n",
    "#         out3 = self.head3(x)\n",
    "\n",
    "#         return out1, out2, out3\n",
    "    \n",
    "\n",
    "class YOLOv3(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.backbone = Darknet53(in_channels=in_channels)\n",
    "        \n",
    "        # Prediction Heads for each scale\n",
    "        self.head1 = PredictionHead(1024, num_classes, ANCHORS[0]) # Large scale\n",
    "        \n",
    "        # --- FIX 1: Update head2 to accept 1024 channels ---\n",
    "        # (512 from upsample + 512 from route2)\n",
    "        self.head2 = PredictionHead(1024, num_classes, ANCHORS[1])  \n",
    "        \n",
    "        # --- FIX 2: Update head3 to accept 512 channels ---\n",
    "        # (256 from upsample + 256 from route3)\n",
    "        self.head3 = PredictionHead(512, num_classes, ANCHORS[2])  \n",
    "\n",
    "        self.conv1 = CNNBlock(1024, 512, kernel_size=1)\n",
    "        \n",
    "        # --- FIX 3: Update conv2 to accept 1024 channels ---\n",
    "        # It takes the output of Scale 2 concat (1024) and reduces it to 256\n",
    "        self.conv2 = CNNBlock(1024, 256, kernel_size=1)\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        route3, route2, route1 = self.backbone(x) # small, medium, large routes\n",
    "        \n",
    "        # Scale 1 prediction (large objects)\n",
    "        out1 = self.head1(route1)\n",
    "        \n",
    "        # Scale 2 prediction (medium objects)\n",
    "        x = self.conv1(route1)\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, route2], dim=1)\n",
    "        out2 = self.head2(x) # Input is now 1024, matches head2\n",
    "\n",
    "        # Scale 3 prediction (small objects)\n",
    "        x = self.conv2(x)    # Input is 1024, matches conv2\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, route3], dim=1)\n",
    "        out3 = self.head3(x) # Input is now 512, matches head3\n",
    "\n",
    "        return out1, out2, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c44aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_boxes(box1, box2, box_format=\"xywh\"):\n",
    "\n",
    "    eps=1e-6\n",
    "\n",
    "    if box_format == \"xywh\":\n",
    "        box1_x1 = box1[..., 0:1] - box1[..., 2:3] / 2\n",
    "        box1_y1 = box1[..., 1:2] - box1[..., 3:4] / 2\n",
    "        box1_x2 = box1[..., 0:1] + box1[..., 2:3] / 2\n",
    "        box1_y2 = box1[..., 1:2] + box1[..., 3:4] / 2\n",
    "\n",
    "        box2_x1 = box2[..., 0:1] - box2[..., 2:3] / 2\n",
    "        box2_y1 = box2[..., 1:2] - box2[..., 3:4] / 2\n",
    "        box2_x2 = box2[..., 0:1] + box2[..., 2:3] / 2\n",
    "        box2_y2 = box2[..., 1:2] + box2[..., 3:4] / 2\n",
    "    else: # box_format == \"xyxy\"\n",
    "        box1_x1, box1_y1, box1_x2, box1_y2 = box1[..., 0:1], box1[..., 1:2], box1[..., 2:3], box1[..., 3:4]\n",
    "        box2_x1, box2_y1, box2_x2, box2_y2 = box2[..., 0:1], box2[..., 1:2], box2[..., 2:3], box2[..., 3:4]\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    inter_w = (x2 - x1).clamp(min=0)\n",
    "    inter_h = (y2 - y1).clamp(min=0)\n",
    "    intersection = inter_w * inter_h \n",
    "\n",
    "    area1 = abs((box1_x2 - box1_x1).clamp(min=0) * (box1_y2 - box1_y1).clamp(min=0))\n",
    "    area2 = abs((box2_x2 - box2_x1).clamp(min=0) * (box2_y2 - box2_y1).clamp(min=0))\n",
    "\n",
    "    union = area1 + area2 - intersection\n",
    "\n",
    "    iou=intersection / (union+eps)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a154fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(bboxes, iou_threshold, confidence_threshold):\n",
    "    # Filter out boxes with low confidence\n",
    "    bboxes = [box for box in bboxes if box[1] > confidence_threshold]\n",
    "    # Sort boxes by confidence score in descending order\n",
    "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
    "    bboxes_after_nms = []\n",
    "\n",
    "    while bboxes:\n",
    "        chosen_box = bboxes.pop(0)\n",
    "        \n",
    "        # Keep only boxes of different classes or with low IoU\n",
    "        bboxes = [\n",
    "            box\n",
    "            for box in bboxes\n",
    "            if box[0] != chosen_box[0] or \n",
    "               iou_boxes(torch.tensor(chosen_box[2:]), torch.tensor(box[2:])) < iou_threshold\n",
    "        ]\n",
    "        \n",
    "        bboxes_after_nms.append(chosen_box)\n",
    "\n",
    "    return bboxes_after_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2d1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RadarDataset(Dataset):\n",
    "#     def __init__(self, image_dir, label_dir, anchors, S, C=1):\n",
    "#         self.image_paths = sorted(glob.glob(os.path.join(image_dir, '*.png')))\n",
    "#         self.label_dir = label_dir\n",
    "#         self.S = S\n",
    "#         self.C = C\n",
    "#         self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2])\n",
    "#         self.num_anchors = self.anchors.shape[0]\n",
    "#         self.num_anchors_per_scale = self.num_anchors // 3\n",
    "#         self.ignore_iou_thresh = 0.5\n",
    "        \n",
    "#         self.transform = transforms.Compose([\n",
    "#             transforms.Grayscale(),\n",
    "#             transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "#             transforms.ToTensor()\n",
    "#         ])\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     # def __getitem__(self, idx):\n",
    "#     #     image_path = self.image_paths[idx]\n",
    "#     #     label_path = os.path.join(self.label_dir, os.path.basename(image_path).replace('.png', '.txt'))\n",
    "#     #     image = Image.open(image_path)\n",
    "#     #     image = self.transform(image)\n",
    "\n",
    "#     #     targets = [torch.zeros((self.num_anchors_per_scale, s, s, 6)) for s in self.S]\n",
    "\n",
    "#     #     if os.path.exists(label_path):\n",
    "#     #         with open(label_path, 'r') as f:\n",
    "#     #             for line in f:\n",
    "#     #                 cls, x, y, w, h = map(float, line.strip().split())\n",
    "                    \n",
    "#     #                 # Find the best anchor for this bounding box across ALL anchors\n",
    "#     #                 ious = iou_boxes(torch.tensor([w, h]), self.anchors)\n",
    "#     #                 best_anchor_idx = ious.argmax()\n",
    "                    \n",
    "#     #                 # Determine which scale and which anchor on that scale it belongs to\n",
    "#     #                 scale_idx = best_anchor_idx // self.num_anchors_per_scale\n",
    "#     #                 anchor_on_scale_idx = best_anchor_idx % self.num_anchors_per_scale\n",
    "                    \n",
    "#     #                 s = self.S[scale_idx]\n",
    "#     #                 i, j = int(s * y), int(s * x) # grid cell\n",
    "                    \n",
    "#     #                 # Check if cell is already taken\n",
    "#     #                 if targets[scale_idx][anchor_on_scale_idx, i, j, 0] == 0:\n",
    "#     #                     targets[scale_idx][anchor_on_scale_idx, i, j, 0] = 1 \n",
    "#     #                     x_cell, y_cell = s * x - j, s * y - i\n",
    "#     #                     w_cell, h_cell = w, h\n",
    "#     #                     box_coords = torch.tensor([x_cell, y_cell, w_cell, h_cell])\n",
    "#     #                     targets[scale_idx][anchor_on_scale_idx, i, j, 1:5] = box_coords\n",
    "#     #                     targets[scale_idx][anchor_on_scale_idx, i, j, 5] = int(cls)\n",
    "\n",
    "#     #     return image, tuple(targets)\n",
    "    \n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image_path = self.image_paths[idx]\n",
    "#         label_path = os.path.join(self.label_dir, os.path.basename(image_path).replace('.png', '.txt'))\n",
    "#         image = Image.open(image_path)\n",
    "#         image = self.transform(image)\n",
    "\n",
    "#         targets = [torch.zeros((self.num_anchors_per_scale, s, s, 6)) for s in self.S]\n",
    "\n",
    "#         if os.path.exists(label_path):\n",
    "#             with open(label_path, 'r') as f:\n",
    "#                 for line in f:\n",
    "#                     cls, x, y, w, h = map(float, line.strip().split())\n",
    "                    \n",
    "#                     # --- FIX STARTS HERE ---\n",
    "#                     # We need to trick iou_boxes into comparing just width/height.\n",
    "#                     # We create boxes centered at (0,0) with the given width/height.\n",
    "                    \n",
    "#                     # Create current box with x=0, y=0, w=w, h=h\n",
    "#                     box_tensor = torch.tensor([0, 0, w, h])\n",
    "                    \n",
    "#                     # Create anchor boxes with x=0, y=0, w=anchor_w, h=anchor_h\n",
    "#                     # self.anchors is (9, 2), we need (9, 4)\n",
    "#                     anchors_xywh = torch.cat([torch.zeros_like(self.anchors), self.anchors], dim=1)\n",
    "                    \n",
    "#                     # Calculate IoU using the padded coordinates\n",
    "#                     ious = iou_boxes(box_tensor, anchors_xywh)\n",
    "#                     # --- FIX ENDS HERE ---\n",
    "\n",
    "#                     best_anchor_idx = ious.argmax()\n",
    "                    \n",
    "#                     # Determine which scale and which anchor on that scale it belongs to\n",
    "#                     scale_idx = best_anchor_idx // self.num_anchors_per_scale\n",
    "#                     anchor_on_scale_idx = best_anchor_idx % self.num_anchors_per_scale\n",
    "                    \n",
    "#                     s = self.S[scale_idx]\n",
    "#                     i, j = int(s * y), int(s * x) # grid cell\n",
    "                    \n",
    "#                     # Check if cell is already taken\n",
    "#                     if targets[scale_idx][anchor_on_scale_idx, i, j, 0] == 0:\n",
    "#                         targets[scale_idx][anchor_on_scale_idx, i, j, 0] = 1 \n",
    "#                         x_cell, y_cell = s * x - j, s * y - i\n",
    "#                         w_cell, h_cell = w, h\n",
    "#                         box_coords = torch.tensor([x_cell, y_cell, w_cell, h_cell])\n",
    "#                         targets[scale_idx][anchor_on_scale_idx, i, j, 1:5] = box_coords\n",
    "#                         targets[scale_idx][anchor_on_scale_idx, i, j, 5] = int(cls)\n",
    "\n",
    "#         return image, tuple(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c5543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadarDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, anchors, S, C=1):\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, '*.png')))\n",
    "        self.label_dir = label_dir\n",
    "        self.S = S\n",
    "        self.C = C\n",
    "        self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2])\n",
    "        self.num_anchors = self.anchors.shape[0]\n",
    "        self.num_anchors_per_scale = self.num_anchors // 3\n",
    "        self.ignore_iou_thresh = 0.5\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label_path = os.path.join(self.label_dir, os.path.basename(image_path).replace('.png', '.txt'))\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        targets = [torch.zeros((self.num_anchors_per_scale, s, s, 6)) for s in self.S]\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    cls, x, y, w, h = map(float, line.strip().split())\n",
    "                    \n",
    "                    # --- PREVIOUS FIX: Fake coordinates for IoU ---\n",
    "                    box_tensor = torch.tensor([0, 0, w, h])\n",
    "                    anchors_xywh = torch.cat([torch.zeros_like(self.anchors), self.anchors], dim=1)\n",
    "                    ious = iou_boxes(box_tensor, anchors_xywh)\n",
    "                    \n",
    "                    best_anchor_idx = ious.argmax()\n",
    "                    \n",
    "                    scale_idx = best_anchor_idx // self.num_anchors_per_scale\n",
    "                    anchor_on_scale_idx = best_anchor_idx % self.num_anchors_per_scale\n",
    "                    \n",
    "                    s = self.S[scale_idx]\n",
    "                    \n",
    "                    # --- NEW FIX STARTS HERE ---\n",
    "                    # Calculate indices\n",
    "                    i, j = int(s * y), int(s * x) \n",
    "                    \n",
    "                    # Clamp indices to ensure they stay within valid bounds [0, s-1]\n",
    "                    # This handles cases where x or y is exactly 1.0\n",
    "                    i = min(i, s - 1)\n",
    "                    j = min(j, s - 1)\n",
    "                    # --- NEW FIX ENDS HERE ---\n",
    "                    \n",
    "                    if targets[scale_idx][anchor_on_scale_idx, i, j, 0] == 0:\n",
    "                        targets[scale_idx][anchor_on_scale_idx, i, j, 0] = 1 \n",
    "                        x_cell, y_cell = s * x - j, s * y - i\n",
    "                        w_cell, h_cell = w, h\n",
    "                        box_coords = torch.tensor([x_cell, y_cell, w_cell, h_cell])\n",
    "                        targets[scale_idx][anchor_on_scale_idx, i, j, 1:5] = box_coords\n",
    "                        targets[scale_idx][anchor_on_scale_idx, i, j, 5] = int(cls)\n",
    "\n",
    "        return image, tuple(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd43406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class YoloLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.mse = nn.MSELoss()\n",
    "#         self.bce = nn.BCEWithLogitsLoss()\n",
    "#         self.lambda_class = 1\n",
    "#         self.lambda_noobj = 10\n",
    "#         self.lambda_obj = 1\n",
    "#         self.lambda_box = 10\n",
    "\n",
    "#     def forward(self, predictions, targets, anchors):\n",
    "#         total_loss = 0\n",
    "        \n",
    "#         # Iterate over the 3 scales\n",
    "#         for i in range(3):\n",
    "#             pred = predictions[i]\n",
    "#             target = targets[i]\n",
    "#             # Anchors for the current scale\n",
    "#             scale_anchors = anchors[i]\n",
    "            \n",
    "#             obj_mask = target[..., 0] == 1\n",
    "#             noobj_mask = target[..., 0] == 0\n",
    "\n",
    "#             # No Object Loss\n",
    "#             noobj_loss = self.bce(\n",
    "#                 (pred[..., 0:1][noobj_mask]), (target[..., 0:1][noobj_mask])\n",
    "#             )\n",
    "\n",
    "#             # Object Loss\n",
    "#             obj_loss = self.bce(\n",
    "#                 (pred[..., 0:1][obj_mask]), (target[..., 0:1][obj_mask])\n",
    "#             )\n",
    "\n",
    "#             # Box Coordinate Loss\n",
    "#             pred[..., 1:3] = torch.sigmoid(pred[..., 1:3]) # x,y\n",
    "#             target[..., 3:5] = torch.log(\n",
    "#                 (1e-16 + target[..., 3:5] / scale_anchors)\n",
    "#             ) # w,h\n",
    "#             box_loss = self.mse(pred[..., 1:5][obj_mask], target[..., 1:5][obj_mask])\n",
    "            \n",
    "#             # Class Loss\n",
    "#             class_loss = self.bce(\n",
    "#                 (pred[..., 5:][obj_mask]), (target[..., 5:][obj_mask].float())\n",
    "#             )\n",
    "            \n",
    "#             total_loss += (\n",
    "#                 self.lambda_box * box_loss\n",
    "#                 + self.lambda_obj * obj_loss\n",
    "#                 + self.lambda_noobj * noobj_loss\n",
    "#                 + self.lambda_class * class_loss\n",
    "#             )\n",
    "            \n",
    "#         return total_loss\n",
    "    \n",
    "\n",
    "# class YoloLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.mse = nn.MSELoss()\n",
    "#         self.bce = nn.BCEWithLogitsLoss()\n",
    "#         self.lambda_class = 1\n",
    "#         self.lambda_noobj = 10\n",
    "#         self.lambda_obj = 1\n",
    "#         self.lambda_box = 10\n",
    "\n",
    "#     def forward(self, predictions, targets, anchors):\n",
    "#         total_loss = 0\n",
    "        \n",
    "#         # Iterate over the 3 scales\n",
    "#         for i in range(3):\n",
    "#             pred = predictions[i]\n",
    "#             target = targets[i]\n",
    "            \n",
    "#             # --- FIX STARTS HERE ---\n",
    "#             # Reshape anchors to (1, 3, 1, 1, 2) to allow broadcasting\n",
    "#             # against target shape (Batch, 3, Grid, Grid, 2)\n",
    "#             scale_anchors = anchors[i].reshape(1, 3, 1, 1, 2)\n",
    "#             # --- FIX ENDS HERE ---\n",
    "            \n",
    "#             obj_mask = target[..., 0] == 1\n",
    "#             noobj_mask = target[..., 0] == 0\n",
    "\n",
    "#             # No Object Loss\n",
    "#             noobj_loss = self.bce(\n",
    "#                 (pred[..., 0:1][noobj_mask]), (target[..., 0:1][noobj_mask])\n",
    "#             )\n",
    "\n",
    "#             # Object Loss\n",
    "#             obj_loss = self.bce(\n",
    "#                 (pred[..., 0:1][obj_mask]), (target[..., 0:1][obj_mask])\n",
    "#             )\n",
    "\n",
    "#             # Box Coordinate Loss\n",
    "#             pred[..., 1:3] = torch.sigmoid(pred[..., 1:3]) # x,y\n",
    "            \n",
    "#             # Now this division works because dimensions align correctly\n",
    "#             target[..., 3:5] = torch.log(\n",
    "#                 (1e-16 + target[..., 3:5] / scale_anchors)\n",
    "#             ) # w,h\n",
    "            \n",
    "#             box_loss = self.mse(pred[..., 1:5][obj_mask], target[..., 1:5][obj_mask])\n",
    "            \n",
    "#             # Class Loss\n",
    "#             class_loss = self.bce(\n",
    "#                 (pred[..., 5:][obj_mask]), (target[..., 5:][obj_mask].float())\n",
    "#             )\n",
    "            \n",
    "#             total_loss += (\n",
    "#                 self.lambda_box * box_loss\n",
    "#                 + self.lambda_obj * obj_loss\n",
    "#                 + self.lambda_noobj * noobj_loss\n",
    "#                 + self.lambda_class * class_loss\n",
    "#             )\n",
    "            \n",
    "#         return total_loss\n",
    "    \n",
    "\n",
    "# class YoloLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.mse = nn.MSELoss()\n",
    "#         self.bce = nn.BCEWithLogitsLoss()\n",
    "#         self.lambda_class = 1\n",
    "#         self.lambda_noobj = 10\n",
    "#         self.lambda_obj = 1\n",
    "#         self.lambda_box = 10\n",
    "\n",
    "#     def forward(self, predictions, targets, anchors):\n",
    "#         total_loss = 0\n",
    "        \n",
    "#         for i in range(3):\n",
    "#             pred = predictions[i]\n",
    "#             target = targets[i]\n",
    "            \n",
    "#             # Reshape anchors for broadcasting (from previous fix)\n",
    "#             scale_anchors = anchors[i].reshape(1, 3, 1, 1, 2)\n",
    "            \n",
    "#             obj_mask = target[..., 0] == 1\n",
    "#             noobj_mask = target[..., 0] == 0\n",
    "\n",
    "#             # No Object Loss\n",
    "#             noobj_loss = self.bce(\n",
    "#                 (pred[..., 0:1][noobj_mask]), (target[..., 0:1][noobj_mask])\n",
    "#             )\n",
    "\n",
    "#             # Object Loss\n",
    "#             obj_loss = self.bce(\n",
    "#                 (pred[..., 0:1][obj_mask]), (target[..., 0:1][obj_mask])\n",
    "#             )\n",
    "\n",
    "#             # Box Coordinate Loss\n",
    "#             pred[..., 1:3] = torch.sigmoid(pred[..., 1:3]) # x,y\n",
    "#             target[..., 3:5] = torch.log(\n",
    "#                 (1e-16 + target[..., 3:5] / scale_anchors)\n",
    "#             ) # w,h\n",
    "#             box_loss = self.mse(pred[..., 1:5][obj_mask], target[..., 1:5][obj_mask])\n",
    "            \n",
    "#             # --- FIX STARTS HERE (Class Loss) ---\n",
    "#             if obj_mask.any():\n",
    "#                 # predictions: (N_objects, num_classes)\n",
    "#                 pred_classes = pred[..., 5:][obj_mask]\n",
    "                \n",
    "#                 # target indices: (N_objects) - select index 5\n",
    "#                 target_indices = target[..., 5][obj_mask].long()\n",
    "                \n",
    "#                 # One-hot encode targets to match prediction shape (N, 11)\n",
    "#                 num_classes = pred_classes.shape[1]\n",
    "#                 target_one_hot = torch.nn.functional.one_hot(target_indices, num_classes=num_classes).float()\n",
    "                \n",
    "#                 class_loss = self.bce(pred_classes, target_one_hot)\n",
    "#             else:\n",
    "#                 # If no objects in this scale/batch, class loss is 0\n",
    "#                 class_loss = torch.tensor(0.0, device=pred.device)\n",
    "#             # --- FIX ENDS HERE ---\n",
    "\n",
    "#             total_loss += (\n",
    "#                 self.lambda_box * box_loss\n",
    "#                 + self.lambda_obj * obj_loss\n",
    "#                 + self.lambda_noobj * noobj_loss\n",
    "#                 + self.lambda_class * class_loss\n",
    "#             )\n",
    "            \n",
    "#         return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.lambda_class = 1\n",
    "        self.lambda_noobj = 10\n",
    "        self.lambda_obj = 1\n",
    "        self.lambda_box = 10\n",
    "\n",
    "    def forward(self, predictions, targets, anchors):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i in range(3):\n",
    "            pred = predictions[i]\n",
    "            target = targets[i]\n",
    "            \n",
    "            # Reshape anchors for broadcasting\n",
    "            scale_anchors = anchors[i].reshape(1, 3, 1, 1, 2)\n",
    "            \n",
    "            obj_mask = target[..., 0] == 1\n",
    "            noobj_mask = target[..., 0] == 0\n",
    "\n",
    "            # No Object Loss\n",
    "            noobj_loss = self.bce(\n",
    "                (pred[..., 0:1][noobj_mask]), (target[..., 0:1][noobj_mask])\n",
    "            )\n",
    "\n",
    "            # Object Loss\n",
    "            obj_loss = self.bce(\n",
    "                (pred[..., 0:1][obj_mask]), (target[..., 0:1][obj_mask])\n",
    "            )\n",
    "\n",
    "            # Box Coordinate Loss\n",
    "            pred[..., 1:3] = torch.sigmoid(pred[..., 1:3]) # x,y\n",
    "            \n",
    "            # --- FIX 1: Numerical Stability for Width/Height ---\n",
    "            target_wh_ratio = target[..., 3:5] / scale_anchors\n",
    "            target_wh_ratio = torch.clamp(target_wh_ratio, min=1e-6)\n",
    "            \n",
    "            target[..., 3:5] = torch.log(target_wh_ratio) \n",
    "            \n",
    "            box_loss = self.mse(pred[..., 1:5][obj_mask], target[..., 1:5][obj_mask])\n",
    "            \n",
    "            # Class Loss (with safe handling for empty batches)\n",
    "            if obj_mask.any():\n",
    "                pred_classes = pred[..., 5:][obj_mask]\n",
    "                target_indices = target[..., 5][obj_mask].long()\n",
    "                num_classes = pred_classes.shape[1]\n",
    "                target_one_hot = torch.nn.functional.one_hot(target_indices, num_classes=num_classes).float()\n",
    "                class_loss = self.bce(pred_classes, target_one_hot)\n",
    "            else:\n",
    "                class_loss = torch.tensor(0.0, device=pred.device)\n",
    "\n",
    "            total_loss += (\n",
    "                self.lambda_box * box_loss\n",
    "                + self.lambda_obj * obj_loss\n",
    "                + self.lambda_noobj * noobj_loss\n",
    "                + self.lambda_class * class_loss\n",
    "            )\n",
    "            \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67b9d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, optimizer, criterion, device, scaled_anchors):\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        loop = tqdm(loader, leave=True)\n",
    "        total_loss = 0\n",
    "        for imgs, labels in loop:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = (\n",
    "                labels[0].to(device),\n",
    "                labels[1].to(device),\n",
    "                labels[2].to(device),\n",
    "            )\n",
    "            \n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, labels, scaled_anchors)\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loop.set_description(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} Average Loss: {total_loss / len(loader)}\")\n",
    "\n",
    "\n",
    "# def train_model(model, loader, optimizer, criterion, device, scaled_anchors):\n",
    "#     model.train()\n",
    "#     # Add a loop bar description\n",
    "#     loop = tqdm(loader, leave=True)\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     for imgs, labels in loop:\n",
    "#         imgs = imgs.to(device)\n",
    "#         labels = (\n",
    "#             labels[0].to(device),\n",
    "#             labels[1].to(device),\n",
    "#             labels[2].to(device),\n",
    "#         )\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         preds = model(imgs)\n",
    "#         loss = criterion(preds, labels, scaled_anchors)\n",
    "        \n",
    "#         loss.backward()\n",
    "        \n",
    "#         # --- FIX 2: Gradient Clipping ---\n",
    "#         # This prevents the gradients from exploding, which causes NaNs\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "        \n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#         loop.set_description(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "#         # Update tqdm to show current loss\n",
    "#         loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "#     # Print average loss for the epoch\n",
    "#     print(f\"Average Loss: {total_loss / len(loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26bda1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image_tensor, boxes):\n",
    "    # Convert tensor to PIL Image\n",
    "    im = transforms.ToPILImage()(image_tensor.cpu())\n",
    "    if im.mode != \"RGB\":\n",
    "        im = im.convert(\"RGB\")\n",
    "        \n",
    "    draw = ImageDraw.Draw(im)\n",
    "    width, height = im.size\n",
    "\n",
    "    for box in boxes:\n",
    "        # box format: [class, conf, x, y, w, h]\n",
    "        class_pred, conf, x, y, w, h = box\n",
    "        \n",
    "        # Convert from center format to top-left corner format\n",
    "        upper_left_x = (x - w / 2) * width\n",
    "        upper_left_y = (y - h / 2) * height\n",
    "        lower_right_x = (x + w / 2) * width\n",
    "        lower_right_y = (y + h / 2) * height\n",
    "\n",
    "        # Draw bounding box\n",
    "        draw.rectangle(\n",
    "            [upper_left_x, upper_left_y, lower_right_x, lower_right_y],\n",
    "            outline=\"red\",\n",
    "            width=2\n",
    "        )\n",
    "        \n",
    "        # Draw label\n",
    "        text = f\"Class {int(class_pred)}: {conf:.2f}\"\n",
    "        text_bbox = draw.textbbox((upper_left_x, upper_left_y), text)\n",
    "        draw.rectangle(text_bbox, fill=\"red\")\n",
    "        draw.text((upper_left_x, upper_left_y), text, fill=\"white\")\n",
    "\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c3a3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_bboxes(loader, model, iou_threshold, confidence_threshold, anchors, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    train_idx = 0\n",
    "    all_pred_boxes = []\n",
    "\n",
    "    scaled_anchors = (\n",
    "        torch.tensor(anchors)\n",
    "        .reshape((3, 3, 2))\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(tqdm(loader, desc=\"Getting BBoxes\")):\n",
    "        x = x.to(device)\n",
    "        \n",
    "        y = (y[0].to(device), y[1].to(device), y[2].to(device))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(x)\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            pred_boxes_single_image = []\n",
    "            # For each scale\n",
    "            for scale_idx in range(3):\n",
    "                S = predictions[scale_idx].shape[2]\n",
    "                # For each anchor on that scale\n",
    "                for anchor_idx in range(3):\n",
    "                    # Get all predictions where objectness is above threshold\n",
    "                    obj_conf = torch.sigmoid(predictions[scale_idx][i, anchor_idx, ..., 0])\n",
    "                    conf_mask = obj_conf > confidence_threshold\n",
    "                    \n",
    "                    if not conf_mask.any():\n",
    "                        continue\n",
    "\n",
    "                    # Extract confident predictions\n",
    "                    preds_on_scale = predictions[scale_idx][i, anchor_idx, conf_mask, :]\n",
    "                    grid_y, grid_x = torch.where(conf_mask)\n",
    "                    \n",
    "                    # Decode bounding box coordinates\n",
    "                    box_coords = torch.sigmoid(preds_on_scale[:, 1:3])\n",
    "                    x_center = (box_coords[:, 0] + grid_x) / S\n",
    "                    y_center = (box_coords[:, 1] + grid_y) / S\n",
    "                    \n",
    "                    # Decode width and height\n",
    "                    anchor = scaled_anchors[scale_idx, anchor_idx]\n",
    "                    box_wh = torch.exp(preds_on_scale[:, 3:5]) * anchor\n",
    "                    w = box_wh[:, 0] / IMG_SIZE\n",
    "                    h = box_wh[:, 1] / IMG_SIZE\n",
    "                    \n",
    "                    # Get class predictions\n",
    "                    class_probs = torch.sigmoid(preds_on_scale[:, 5:])\n",
    "                    class_conf, class_label = torch.max(class_probs, dim=1)\n",
    "                    \n",
    "                    # Combine into [class, conf, x, y, w, h] format\n",
    "                    final_conf = (torch.sigmoid(preds_on_scale[:, 0]) * class_conf).float()\n",
    "                    \n",
    "                    # Filter again by the final confidence\n",
    "                    final_conf_mask = final_conf > confidence_threshold\n",
    "                    if not final_conf_mask.any():\n",
    "                        continue\n",
    "                        \n",
    "                    pred_boxes_batch = torch.cat([\n",
    "                        class_label[final_conf_mask].float().unsqueeze(1),\n",
    "                        final_conf[final_conf_mask].unsqueeze(1),\n",
    "                        x_center[final_conf_mask].unsqueeze(1),\n",
    "                        y_center[final_conf_mask].unsqueeze(1),\n",
    "                        w[final_conf_mask].unsqueeze(1),\n",
    "                        h[final_conf_mask].unsqueeze(1)\n",
    "                    ], dim=1)\n",
    "                    \n",
    "                    pred_boxes_single_image.extend(pred_boxes_batch.tolist())\n",
    "\n",
    "            # Run NMS on all boxes for this image\n",
    "            nms_boxes = non_max_suppression(pred_boxes_single_image, iou_threshold, confidence_threshold)\n",
    "            for nms_box in nms_boxes:\n",
    "                all_pred_boxes.append([train_idx] + nms_box)\n",
    "            train_idx += 1\n",
    "            \n",
    "    model.train()\n",
    "    return all_pred_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8132a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(pred_boxes, true_boxes, iou_threshold=0.5, num_classes=11):\n",
    "    average_precisions = []\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        detections = [d for d in pred_boxes if d[1] == c]\n",
    "        ground_truths = [gt for gt in true_boxes if gt[1] == c]\n",
    "\n",
    "        # Count how many ground truth boxes are in each image\n",
    "        amount_bboxes = Counter(gt[0] for gt in ground_truths)\n",
    "        for key, val in amount_bboxes.items():\n",
    "            amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "        # Sort detections by confidence\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = torch.zeros(len(detections))\n",
    "        FP = torch.zeros(len(detections))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "        \n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "            # Get all ground truth boxes for the same image as the detection\n",
    "            ground_truth_img = [\n",
    "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
    "            ]\n",
    "\n",
    "            best_iou = 0\n",
    "            best_gt_idx = -1\n",
    "\n",
    "            for idx, gt in enumerate(ground_truth_img):\n",
    "                iou = iou_boxes(torch.tensor(detection[1:]), torch.tensor(gt[1:]))\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "\n",
    "            if best_iou > iou_threshold:\n",
    "                # Check if we haven't already matched this ground truth box\n",
    "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "                    TP[detection_idx] = 1 # Mark as True Positive\n",
    "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1 # It's a duplicate detection\n",
    "            else:\n",
    "                FP[detection_idx] = 1 # Failed to meet IoU threshold\n",
    "\n",
    "        # Calculate precision and recall\n",
    "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "        recalls = TP_cumsum / (total_true_bboxes)\n",
    "        precisions = TP_cumsum / (TP_cumsum + FP_cumsum)\n",
    "        \n",
    "        # Integrate under the precision-recall curve\n",
    "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "        average_precisions.append(torch.trapz(precisions, recalls))\n",
    "\n",
    "    return sum(average_precisions) / (len(average_precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9a0bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, device):\n",
    "    print(\"\\nCalculating mAP on dataset \")\n",
    "    model.to(device)\n",
    "    pred_boxes = get_all_bboxes(\n",
    "        loader, model, \n",
    "        iou_threshold=IOU_THRESHOLD, \n",
    "        confidence_threshold=CONFIDENCE_THRESHOLD, \n",
    "        anchors=ANCHORS, \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    map_val = mean_average_precision(pred_boxes, iou_threshold=IOU_THRESHOLD, num_classes=NUM_CLASSES)\n",
    "    print(f\"mAP: {map_val:.4f}\")\n",
    "    return map_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e6bcd",
   "metadata": {},
   "source": [
    "# Training on the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fc042d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1751/1751 [17:26<00:00,  1.67it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 1751/1751 [17:25<00:00,  1.68it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 1751/1751 [17:25<00:00,  1.67it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 1751/1751 [17:36<00:00,  1.66it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 1751/1751 [17:36<00:00,  1.66it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 1751/1751 [18:06<00:00,  1.61it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 1751/1751 [17:26<00:00,  1.67it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 1751/1751 [17:28<00:00,  1.67it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 1751/1751 [16:46<00:00,  1.74it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 1751/1751 [17:12<00:00,  1.70it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 1751/1751 [17:09<00:00,  1.70it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 1751/1751 [17:16<00:00,  1.69it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 1751/1751 [15:33<00:00,  1.88it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 1751/1751 [14:36<00:00,  2.00it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 1751/1751 [16:54<00:00,  1.73it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 1751/1751 [17:29<00:00,  1.67it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 1751/1751 [15:59<00:00,  1.82it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 1751/1751 [14:25<00:00,  2.02it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 1751/1751 [17:01<00:00,  1.71it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 1751/1751 [15:38<00:00,  1.87it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 1751/1751 [15:55<00:00,  1.83it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 1751/1751 [15:59<00:00,  1.82it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 1751/1751 [17:16<00:00,  1.69it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 1751/1751 [15:54<00:00,  1.84it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 1751/1751 [14:33<00:00,  2.00it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 1751/1751 [13:27<00:00,  2.17it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 1751/1751 [12:06<00:00,  2.41it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 1751/1751 [08:53<00:00,  3.28it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 1751/1751 [08:22<00:00,  3.48it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 1751/1751 [12:01<00:00,  2.43it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 1751/1751 [16:12<00:00,  1.80it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 1751/1751 [14:36<00:00,  2.00it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 1751/1751 [12:22<00:00,  2.36it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 1751/1751 [09:34<00:00,  3.05it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 1751/1751 [11:55<00:00,  2.45it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 1751/1751 [15:38<00:00,  1.87it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 1751/1751 [17:11<00:00,  1.70it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 1751/1751 [16:24<00:00,  1.78it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 1751/1751 [14:46<00:00,  1.98it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 1751/1751 [13:17<00:00,  2.20it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 1751/1751 [12:00<00:00,  2.43it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 1751/1751 [09:22<00:00,  3.11it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 1751/1751 [08:17<00:00,  3.52it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 1751/1751 [06:58<00:00,  4.18it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 1751/1751 [08:00<00:00,  3.64it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 1751/1751 [08:04<00:00,  3.61it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 1751/1751 [08:13<00:00,  3.55it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 1751/1751 [08:04<00:00,  3.61it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 1751/1751 [08:43<00:00,  3.35it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Average Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 1751/1751 [16:35<00:00,  1.76it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Average Loss: nan\n",
      "\n",
      "Calculating mAP on dataset \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting BBoxes: 100%|██████████| 1751/1751 [09:41<00:00,  3.01it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mean_average_precision() missing 1 required positional argument: 'true_boxes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     32\u001b[0m     train_model(model, loader, optimizer, criterion, device, scaled_anchors)\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mcheck_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Evaluation: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m check_accuracy(loader, model, device)\n",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36mcheck_accuracy\u001b[0;34m(loader, model, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m pred_boxes \u001b[38;5;241m=\u001b[39m get_all_bboxes(\n\u001b[1;32m      5\u001b[0m     loader, model, \n\u001b[1;32m      6\u001b[0m     iou_threshold\u001b[38;5;241m=\u001b[39mIOU_THRESHOLD, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m map_val \u001b[38;5;241m=\u001b[39m \u001b[43mmean_average_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_boxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIOU_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CLASSES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmAP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmap_val\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m map_val\n",
      "\u001b[0;31mTypeError\u001b[0m: mean_average_precision() missing 1 required positional argument: 'true_boxes'"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     print(\"Training on 1T dataset: \")\n",
    "#     # training on the 1T dataset \n",
    "#     model_1T, class_names,test_image_dir_1T,test_label_dir_1T, train_losses_1T, val_losses_1T, mAPs_1T, mAP50s_1T, mAP75s_1T,train_loader_1T= train(\n",
    "#         base_dir=r\"/home/abdullah/YOLO_BTP/RadDet_128_1T/RadDet40k128HW001Tv2\",\n",
    "#         num_epochs=100,\n",
    "#         save_name=\"yolov1_1T_with_and_nms_threshold_0.5_and_epoch100_and_patience_35_lr1e4_mAP_27thOct.pt\"\n",
    "#     )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = \"/home/abdullah/YOLO_BTP/RadDet_128_1T/RadDet40k128HW001Tv2/images/train\"\n",
    "    label_dir = \"/home/abdullah/YOLO_BTP/RadDet_128_1T/RadDet40k128HW001Tv2/labels/train\"\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Anchors for loss calculation \n",
    "    scaled_anchors = (\n",
    "        torch.tensor(ANCHORS) / torch.tensor([IMG_SIZE, IMG_SIZE])\n",
    "    ).to(device)\n",
    "\n",
    "    dataset = RadarDataset(image_dir, label_dir, anchors=ANCHORS, S=S, C=NUM_CLASSES)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = YOLOv3(in_channels=1, num_classes=NUM_CLASSES).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    criterion = YoloLoss()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        train_model(model, loader, optimizer, criterion, device, scaled_anchors)\n",
    "        check_accuracy(loader, model, device)\n",
    "    \n",
    "    print(\"\\nFinal Evaluation: \")\n",
    "    check_accuracy(loader, model, device)\n",
    "    \n",
    "    print(\"\\nVisualizing a sample prediction: \")\n",
    "    model.eval()\n",
    "    x, y = next(iter(loader))\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "    \n",
    "    all_preds = get_all_bboxes(\n",
    "        [(x, y)], model, IOU_THRESHOLD, CONFIDENCE_THRESHOLD, ANCHORS, device\n",
    "    )\n",
    "    \n",
    "    # Filter boxes for the first image in the batch\n",
    "    boxes_for_image_0 = [box[1:] for box in all_preds if box[0] == 0]\n",
    "    \n",
    "    plot_image(x[0], boxes_for_image_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cfbcd7",
   "metadata": {},
   "source": [
    "## rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a95c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1751 [00:00<11:11,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1751 [00:00<09:19,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1751 [00:00<07:45,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1751 [00:01<07:45,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1751 [00:01<07:46,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1751 [00:01<07:51,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/1751 [00:01<07:32,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1751 [00:02<07:40,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1751 [00:02<07:41,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1751 [00:02<07:47,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1751 [00:03<06:59,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1751 [00:03<06:59,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1751 [00:03<07:16,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/1751 [00:03<07:31,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/1751 [00:04<07:36,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/1751 [00:04<07:18,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/1751 [00:04<06:52,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/1751 [00:04<06:56,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/1751 [00:05<07:18,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/1751 [00:05<07:20,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 22/1751 [00:05<06:58,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 23/1751 [00:05<06:49,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 24/1751 [00:06<06:57,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 25/1751 [00:06<07:07,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 26/1751 [00:06<06:44,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 27/1751 [00:06<06:48,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 28/1751 [00:07<06:39,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 29/1751 [00:07<06:51,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 31/1751 [00:07<06:25,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 32/1751 [00:07<06:27,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 33/1751 [00:08<06:39,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 35/1751 [00:08<06:26,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 36/1751 [00:08<06:29,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 37/1751 [00:09<06:23,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 38/1751 [00:09<06:39,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 39/1751 [00:09<06:40,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 40/1751 [00:09<06:33,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 41/1751 [00:10<06:42,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 42/1751 [00:10<06:49,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 43/1751 [00:10<06:57,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 44/1751 [00:10<06:35,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 46/1751 [00:11<06:24,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 48/1751 [00:11<06:02,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 49/1751 [00:11<05:47,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 51/1751 [00:12<05:48,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 53/1751 [00:12<05:39,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 55/1751 [00:13<05:25,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 57/1751 [00:13<05:25,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 59/1751 [00:13<05:31,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 61/1751 [00:14<05:25,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 62/1751 [00:14<05:46,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 63/1751 [00:14<06:22,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 65/1751 [00:15<06:06,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 66/1751 [00:15<06:19,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 67/1751 [00:15<06:30,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 68/1751 [00:15<06:41,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 69/1751 [00:16<06:44,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 70/1751 [00:16<06:40,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 71/1751 [00:16<06:32,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 72/1751 [00:16<06:49,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 74/1751 [00:17<06:23,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 75/1751 [00:17<06:19,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 76/1751 [00:17<06:34,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 77/1751 [00:18<06:47,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 78/1751 [00:18<06:45,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 80/1751 [00:18<06:09,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 81/1751 [00:18<06:09,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 83/1751 [00:19<05:44,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 84/1751 [00:19<05:49,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 85/1751 [00:19<05:56,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 86/1751 [00:19<05:59,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 87/1751 [00:20<05:52,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 89/1751 [00:20<05:25,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 91/1751 [00:20<05:21,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 92/1751 [00:21<05:26,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 93/1751 [00:21<05:37,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 94/1751 [00:21<06:19,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 95/1751 [00:21<06:48,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 96/1751 [00:22<06:25,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 97/1751 [00:22<06:30,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 98/1751 [00:22<06:23,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 99/1751 [00:22<06:40,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 100/1751 [00:23<06:34,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 101/1751 [00:23<06:16,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 102/1751 [00:23<06:27,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 103/1751 [00:23<06:38,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 104/1751 [00:24<06:47,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 105/1751 [00:24<06:24,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 106/1751 [00:24<06:34,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 107/1751 [00:24<06:30,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 108/1751 [00:24<06:44,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 109/1751 [00:25<06:41,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 110/1751 [00:25<06:25,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 111/1751 [00:25<06:35,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 112/1751 [00:25<06:43,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 114/1751 [00:26<06:23,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 115/1751 [00:26<06:33,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 116/1751 [00:26<06:28,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 117/1751 [00:27<06:40,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 119/1751 [00:27<06:14,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 120/1751 [00:27<06:12,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 121/1751 [00:28<06:16,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 123/1751 [00:28<05:59,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 124/1751 [00:28<05:58,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 125/1751 [00:28<05:53,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 127/1751 [00:29<05:44,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 128/1751 [00:29<05:31,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 129/1751 [00:29<05:38,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 130/1751 [00:30<05:56,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 131/1751 [00:30<06:33,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 132/1751 [00:30<06:24,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 133/1751 [00:30<06:24,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 134/1751 [00:30<06:22,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 135/1751 [00:31<06:37,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 137/1751 [00:31<06:14,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 138/1751 [00:31<06:29,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 139/1751 [00:32<06:57,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 140/1751 [00:32<07:13,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 141/1751 [00:32<06:53,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 142/1751 [00:33<07:02,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 143/1751 [00:33<06:57,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 144/1751 [00:33<07:11,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 146/1751 [00:34<06:40,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 147/1751 [00:34<06:46,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 148/1751 [00:34<06:59,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 149/1751 [00:34<07:08,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 150/1751 [00:35<07:13,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 151/1751 [00:35<07:05,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 152/1751 [00:35<06:47,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 153/1751 [00:35<06:42,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 154/1751 [00:36<07:05,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 155/1751 [00:36<07:15,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 156/1751 [00:36<06:53,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 157/1751 [00:37<06:59,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 158/1751 [00:37<07:05,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 159/1751 [00:37<07:17,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 160/1751 [00:37<06:59,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 161/1751 [00:38<06:52,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 162/1751 [00:38<06:35,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 163/1751 [00:38<06:45,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 165/1751 [00:39<06:09,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 166/1751 [00:39<06:06,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 167/1751 [00:39<06:18,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 168/1751 [00:39<06:26,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 169/1751 [00:39<06:23,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 171/1751 [00:40<05:48,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 172/1751 [00:40<05:55,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 174/1751 [00:41<05:21,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n",
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 175/1751 [00:41<05:27,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 176/1751 [00:41<05:35,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 177/1751 [00:41<05:43,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 178/1751 [00:42<06:11,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loss is NaN, skipping step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 539\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 539\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaled_anchors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# Evaluate every 5 epochs to save time, or every epoch if dataset is small\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[28], line 488\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, loader, optimizer, criterion, device, scaled_anchors)\u001b[0m\n\u001b[1;32m    485\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# Check for NaN in inputs\u001b[39;00m\n\u001b[0;32m--> 488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(imgs)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: NaN input image detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image, ImageDraw\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# import glob\n",
    "# from collections import Counter\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # --- HYPERPARAMETERS ---\n",
    "# IMG_SIZE = 416\n",
    "# BATCH_SIZE = 8\n",
    "# LEARNING_RATE = 1e-4 # Slightly increased for stability with Adam\n",
    "# EPOCHS = 50 \n",
    "# NUM_CLASSES = 11\n",
    "# CONFIDENCE_THRESHOLD = 0.5\n",
    "# IOU_THRESHOLD = 0.5\n",
    "# ANCHORS = [\n",
    "#     [(116, 90), (156, 198), (373, 326)],  # Scale 1 (13x13)\n",
    "#     [(30, 61), (62, 45), (59, 119)],      # Scale 2 (26x26)\n",
    "#     [(10, 13), (16, 30), (33, 23)],       # Scale 3 (52x52)\n",
    "# ]\n",
    "# S = [IMG_SIZE // 32, IMG_SIZE // 16, IMG_SIZE // 8]\n",
    "\n",
    "# # --- MODEL COMPONENTS ---\n",
    "# class CNNBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, use_bn=True, **kwargs):\n",
    "#         super().__init__()\n",
    "#         self.conv = nn.Conv2d(in_channels, out_channels, bias=not use_bn, **kwargs)\n",
    "#         self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
    "#         self.leaky = nn.LeakyReLU(0.1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.leaky(self.bn(self.conv(x)))\n",
    "\n",
    "# class ResidualBlock(nn.Module):\n",
    "#     def __init__(self, channels, num_repeats=1):\n",
    "#         super().__init__()\n",
    "#         self.layers = nn.ModuleList()\n",
    "#         for _ in range(num_repeats):\n",
    "#             self.layers += [\n",
    "#                 nn.Sequential(\n",
    "#                     CNNBlock(channels, channels // 2, kernel_size=1),\n",
    "#                     CNNBlock(channels // 2, channels, kernel_size=3, padding=1),\n",
    "#                 )\n",
    "#             ]\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         for layer in self.layers:\n",
    "#             x = x + layer(x)\n",
    "#         return x\n",
    "\n",
    "# class PredictionHead(nn.Module):\n",
    "#     def __init__(self, in_channels, num_classes, anchors):\n",
    "#         super().__init__()\n",
    "#         self.num_classes = num_classes\n",
    "#         self.anchors = anchors\n",
    "#         self.num_anchors = len(anchors)\n",
    "        \n",
    "#         self.head = nn.Sequential(\n",
    "#             CNNBlock(in_channels, in_channels * 2, kernel_size=3, padding=1),\n",
    "#             CNNBlock(in_channels * 2, (self.num_anchors * (5 + num_classes)), use_bn=False, kernel_size=1),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.head(x)\n",
    "#         out = out.view(x.shape[0], self.num_anchors, 5 + self.num_classes, x.shape[2], x.shape[3])\n",
    "#         out = out.permute(0, 1, 3, 4, 2)\n",
    "#         return out\n",
    "\n",
    "# class Darknet53(nn.Module):\n",
    "#     def __init__(self, in_channels=1):\n",
    "#         super().__init__()\n",
    "#         self.in_channels = in_channels\n",
    "#         self.layers = nn.ModuleList([\n",
    "#             CNNBlock(in_channels, 32, kernel_size=3, padding=1),\n",
    "#             CNNBlock(32, 64, kernel_size=3, padding=1, stride=2),\n",
    "#             ResidualBlock(64, num_repeats=1),\n",
    "#             CNNBlock(64, 128, kernel_size=3, padding=1, stride=2),\n",
    "#             ResidualBlock(128, num_repeats=2),\n",
    "#             CNNBlock(128, 256, kernel_size=3, padding=1, stride=2),\n",
    "#             ResidualBlock(256, num_repeats=8),\n",
    "#             CNNBlock(256, 512, kernel_size=3, padding=1, stride=2),\n",
    "#             ResidualBlock(512, num_repeats=8),\n",
    "#             CNNBlock(512, 1024, kernel_size=3, padding=1, stride=2),\n",
    "#             ResidualBlock(1024, num_repeats=4),\n",
    "#         ])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         outputs = []\n",
    "#         for i, layer in enumerate(self.layers):\n",
    "#             x = layer(x)\n",
    "#             if i in [6, 8]:\n",
    "#                 outputs.append(x)\n",
    "#         outputs.append(x)\n",
    "#         return outputs[0], outputs[1], outputs[2]\n",
    "\n",
    "# class YOLOv3(nn.Module):\n",
    "#     def __init__(self, in_channels=1, num_classes=11):\n",
    "#         super().__init__()\n",
    "#         self.num_classes = num_classes\n",
    "#         self.in_channels = in_channels\n",
    "#         self.backbone = Darknet53(in_channels=in_channels)\n",
    "        \n",
    "#         # FIXED: Corrected input channels for heads and convs\n",
    "#         self.head1 = PredictionHead(1024, num_classes, ANCHORS[0]) \n",
    "#         self.head2 = PredictionHead(1024, num_classes, ANCHORS[1]) # Input 1024 (512+512)\n",
    "#         self.head3 = PredictionHead(512, num_classes, ANCHORS[2])  # Input 512 (256+256)\n",
    "\n",
    "#         self.conv1 = CNNBlock(1024, 512, kernel_size=1)\n",
    "#         self.conv2 = CNNBlock(1024, 256, kernel_size=1) # Input 1024\n",
    "#         self.upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         route3, route2, route1 = self.backbone(x)\n",
    "        \n",
    "#         out1 = self.head1(route1)\n",
    "        \n",
    "#         x = self.conv1(route1)\n",
    "#         x = self.upsample(x)\n",
    "#         x = torch.cat([x, route2], dim=1)\n",
    "#         out2 = self.head2(x)\n",
    "\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.upsample(x)\n",
    "#         x = torch.cat([x, route3], dim=1)\n",
    "#         out3 = self.head3(x)\n",
    "\n",
    "#         return out1, out2, out3\n",
    "\n",
    "# # --- UTILS ---\n",
    "# def iou_boxes(box1, box2, box_format=\"xywh\"):\n",
    "#     eps=1e-6\n",
    "#     if box_format == \"xywh\":\n",
    "#         box1_x1 = box1[..., 0:1] - box1[..., 2:3] / 2\n",
    "#         box1_y1 = box1[..., 1:2] - box1[..., 3:4] / 2\n",
    "#         box1_x2 = box1[..., 0:1] + box1[..., 2:3] / 2\n",
    "#         box1_y2 = box1[..., 1:2] + box1[..., 3:4] / 2\n",
    "#         box2_x1 = box2[..., 0:1] - box2[..., 2:3] / 2\n",
    "#         box2_y1 = box2[..., 1:2] - box2[..., 3:4] / 2\n",
    "#         box2_x2 = box2[..., 0:1] + box2[..., 2:3] / 2\n",
    "#         box2_y2 = box2[..., 1:2] + box2[..., 3:4] / 2\n",
    "#     else:\n",
    "#         box1_x1, box1_y1, box1_x2, box1_y2 = box1[..., 0:1], box1[..., 1:2], box1[..., 2:3], box1[..., 3:4]\n",
    "#         box2_x1, box2_y1, box2_x2, box2_y2 = box2[..., 0:1], box2[..., 1:2], box2[..., 2:3], box2[..., 3:4]\n",
    "\n",
    "#     x1 = torch.max(box1_x1, box2_x1)\n",
    "#     y1 = torch.max(box1_y1, box2_y1)\n",
    "#     x2 = torch.min(box1_x2, box2_x2)\n",
    "#     y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "#     inter_w = (x2 - x1).clamp(min=0)\n",
    "#     inter_h = (y2 - y1).clamp(min=0)\n",
    "#     intersection = inter_w * inter_h \n",
    "\n",
    "#     area1 = abs((box1_x2 - box1_x1).clamp(min=0) * (box1_y2 - box1_y1).clamp(min=0))\n",
    "#     area2 = abs((box2_x2 - box2_x1).clamp(min=0) * (box2_y2 - box2_y1).clamp(min=0))\n",
    "\n",
    "#     union = area1 + area2 - intersection\n",
    "#     return intersection / (union+eps)\n",
    "\n",
    "# def non_max_suppression(bboxes, iou_threshold, confidence_threshold):\n",
    "#     bboxes = [box for box in bboxes if box[1] > confidence_threshold]\n",
    "#     bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
    "#     bboxes_after_nms = []\n",
    "\n",
    "#     while bboxes:\n",
    "#         chosen_box = bboxes.pop(0)\n",
    "#         bboxes = [\n",
    "#             box for box in bboxes\n",
    "#             if box[0] != chosen_box[0] or \n",
    "#             iou_boxes(torch.tensor(chosen_box[2:]), torch.tensor(box[2:])) < iou_threshold\n",
    "#         ]\n",
    "#         bboxes_after_nms.append(chosen_box)\n",
    "#     return bboxes_after_nms\n",
    "\n",
    "# # --- DATASET ---\n",
    "# class RadarDataset(Dataset):\n",
    "#     def __init__(self, image_dir, label_dir, anchors, S, C=1):\n",
    "#         self.image_paths = sorted(glob.glob(os.path.join(image_dir, '*.png')))\n",
    "#         self.label_dir = label_dir\n",
    "#         self.S = S\n",
    "#         self.C = C\n",
    "#         self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2])\n",
    "#         self.num_anchors = self.anchors.shape[0]\n",
    "#         self.num_anchors_per_scale = self.num_anchors // 3\n",
    "        \n",
    "#         self.transform = transforms.Compose([\n",
    "#             transforms.Grayscale(),\n",
    "#             transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "#             transforms.ToTensor()\n",
    "#         ])\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image_path = self.image_paths[idx]\n",
    "#         label_path = os.path.join(self.label_dir, os.path.basename(image_path).replace('.png', '.txt'))\n",
    "#         image = Image.open(image_path)\n",
    "#         image = self.transform(image)\n",
    "\n",
    "#         targets = [torch.zeros((self.num_anchors_per_scale, s, s, 6)) for s in self.S]\n",
    "\n",
    "#         if os.path.exists(label_path):\n",
    "#             with open(label_path, 'r') as f:\n",
    "#                 for line in f:\n",
    "#                     data = list(map(float, line.strip().split()))\n",
    "#                     if len(data) < 5: continue\n",
    "#                     cls, x, y, w, h = data\n",
    "                    \n",
    "#                     # FIXED: Padding for IoU calculation\n",
    "#                     box_tensor = torch.tensor([0, 0, w, h])\n",
    "#                     anchors_xywh = torch.cat([torch.zeros_like(self.anchors), self.anchors], dim=1)\n",
    "#                     ious = iou_boxes(box_tensor, anchors_xywh)\n",
    "#                     best_anchor_idx = ious.argmax()\n",
    "                    \n",
    "#                     scale_idx = best_anchor_idx // self.num_anchors_per_scale\n",
    "#                     anchor_on_scale_idx = best_anchor_idx % self.num_anchors_per_scale\n",
    "                    \n",
    "#                     s = self.S[scale_idx]\n",
    "#                     # FIXED: Clamping indices to avoid out of bounds\n",
    "#                     i, j = int(s * y), int(s * x)\n",
    "#                     i = min(i, s - 1)\n",
    "#                     j = min(j, s - 1)\n",
    "                    \n",
    "#                     if targets[scale_idx][anchor_on_scale_idx, i, j, 0] == 0:\n",
    "#                         targets[scale_idx][anchor_on_scale_idx, i, j, 0] = 1 \n",
    "#                         x_cell, y_cell = s * x - j, s * y - i\n",
    "#                         w_cell, h_cell = w, h\n",
    "#                         box_coords = torch.tensor([x_cell, y_cell, w_cell, h_cell])\n",
    "#                         targets[scale_idx][anchor_on_scale_idx, i, j, 1:5] = box_coords\n",
    "#                         targets[scale_idx][anchor_on_scale_idx, i, j, 5] = int(cls)\n",
    "#         return image, tuple(targets)\n",
    "\n",
    "# # --- LOSS FUNCTION ---\n",
    "# class YoloLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.mse = nn.MSELoss()\n",
    "#         self.bce = nn.BCEWithLogitsLoss()\n",
    "#         self.lambda_class = 1\n",
    "#         self.lambda_noobj = 10\n",
    "#         self.lambda_obj = 1\n",
    "#         self.lambda_box = 10\n",
    "\n",
    "#     def forward(self, predictions, targets, anchors):\n",
    "#         total_loss = 0\n",
    "        \n",
    "#         for i in range(3):\n",
    "#             pred = predictions[i]\n",
    "#             target = targets[i]\n",
    "            \n",
    "#             # Reshape anchors: (1, 3, 1, 1, 2)\n",
    "#             scale_anchors = anchors[i].reshape(1, 3, 1, 1, 2)\n",
    "            \n",
    "#             obj_mask = target[..., 0] == 1\n",
    "#             noobj_mask = target[..., 0] == 0\n",
    "\n",
    "#             # --- No Object Loss ---\n",
    "#             noobj_loss = self.bce(\n",
    "#                 (pred[..., 0:1][noobj_mask]), (target[..., 0:1][noobj_mask])\n",
    "#             )\n",
    "\n",
    "#             # --- Object Loss ---\n",
    "#             obj_loss = self.bce(\n",
    "#                 (pred[..., 0:1][obj_mask]), (target[..., 0:1][obj_mask])\n",
    "#             )\n",
    "\n",
    "#             # --- Box Coordinates Loss ---\n",
    "#             # FIXED: Calculate loss ONLY on the masked valid objects to avoid log(0)\n",
    "#             if obj_mask.any():\n",
    "#                 # Extract valid predictions and targets\n",
    "#                 pred_boxes = pred[..., 1:5][obj_mask]\n",
    "#                 target_boxes = target[..., 1:5][obj_mask]\n",
    "#                 anchor_boxes = scale_anchors.expand_as(target[..., 3:5])[obj_mask]\n",
    "                \n",
    "#                 # Sigmoid for x, y\n",
    "#                 pred_xy = torch.sigmoid(pred_boxes[..., 0:2])\n",
    "#                 target_xy = target_boxes[..., 0:2]\n",
    "                \n",
    "#                 # Process w, h\n",
    "#                 # Instead of mutating target in place, we calculate the value needed for MSE\n",
    "#                 # Target for network output is log(target_w / anchor_w)\n",
    "#                 target_wh = torch.log((target_boxes[..., 2:4] / anchor_boxes) + 1e-6)\n",
    "#                 pred_wh = pred_boxes[..., 2:4]\n",
    "\n",
    "#                 box_loss = self.mse(pred_xy, target_xy) + self.mse(pred_wh, target_wh)\n",
    "#             else:\n",
    "#                 box_loss = torch.tensor(0.0, device=pred.device)\n",
    "\n",
    "#             # --- Class Loss ---\n",
    "#             if obj_mask.any():\n",
    "#                 pred_classes = pred[..., 5:][obj_mask]\n",
    "#                 target_indices = target[..., 5][obj_mask].long()\n",
    "                \n",
    "#                 # One-hot encode\n",
    "#                 num_classes = pred_classes.shape[1]\n",
    "#                 target_one_hot = torch.nn.functional.one_hot(target_indices, num_classes=num_classes).float()\n",
    "                \n",
    "#                 class_loss = self.bce(pred_classes, target_one_hot)\n",
    "#             else:\n",
    "#                 class_loss = torch.tensor(0.0, device=pred.device)\n",
    "\n",
    "#             total_loss += (\n",
    "#                 self.lambda_box * box_loss\n",
    "#                 + self.lambda_obj * obj_loss\n",
    "#                 + self.lambda_noobj * noobj_loss\n",
    "#                 + self.lambda_class * class_loss\n",
    "#             )\n",
    "            \n",
    "#         return total_loss\n",
    "\n",
    "# # --- EVALUATION ---\n",
    "# def get_all_bboxes(loader, model, iou_threshold, confidence_threshold, anchors, device=\"cpu\"):\n",
    "#     model.eval()\n",
    "#     train_idx = 0\n",
    "#     all_pred_boxes = []\n",
    "    \n",
    "#     scaled_anchors = (torch.tensor(anchors).reshape((3, 3, 2)).to(device))\n",
    "\n",
    "#     for batch_idx, (x, y) in enumerate(tqdm(loader, desc=\"Getting BBoxes\", leave=False)):\n",
    "#         x = x.to(device)\n",
    "#         with torch.no_grad():\n",
    "#             predictions = model(x)\n",
    "\n",
    "#         batch_size = x.shape[0]\n",
    "#         for i in range(batch_size):\n",
    "#             pred_boxes_single_image = []\n",
    "#             for scale_idx in range(3):\n",
    "#                 S = predictions[scale_idx].shape[2]\n",
    "#                 for anchor_idx in range(3):\n",
    "#                     obj_conf = torch.sigmoid(predictions[scale_idx][i, anchor_idx, ..., 0])\n",
    "#                     conf_mask = obj_conf > confidence_threshold\n",
    "                    \n",
    "#                     if not conf_mask.any(): continue\n",
    "\n",
    "#                     preds_on_scale = predictions[scale_idx][i, anchor_idx, conf_mask, :]\n",
    "#                     grid_y, grid_x = torch.where(conf_mask)\n",
    "                    \n",
    "#                     box_coords = torch.sigmoid(preds_on_scale[:, 1:3])\n",
    "#                     x_center = (box_coords[:, 0] + grid_x) / S\n",
    "#                     y_center = (box_coords[:, 1] + grid_y) / S\n",
    "                    \n",
    "#                     anchor = scaled_anchors[scale_idx, anchor_idx]\n",
    "#                     # FIXED: clamp exp to avoid infinity\n",
    "#                     box_wh_preds = torch.clamp(preds_on_scale[:, 3:5], max=10) \n",
    "#                     box_wh = torch.exp(box_wh_preds) * anchor\n",
    "#                     w = box_wh[:, 0] / IMG_SIZE\n",
    "#                     h = box_wh[:, 1] / IMG_SIZE\n",
    "                    \n",
    "#                     class_probs = torch.sigmoid(preds_on_scale[:, 5:])\n",
    "#                     class_conf, class_label = torch.max(class_probs, dim=1)\n",
    "#                     final_conf = (torch.sigmoid(preds_on_scale[:, 0]) * class_conf).float()\n",
    "                    \n",
    "#                     final_conf_mask = final_conf > confidence_threshold\n",
    "#                     if not final_conf_mask.any(): continue\n",
    "                        \n",
    "#                     pred_boxes_batch = torch.cat([\n",
    "#                         class_label[final_conf_mask].float().unsqueeze(1),\n",
    "#                         final_conf[final_conf_mask].unsqueeze(1),\n",
    "#                         x_center[final_conf_mask].unsqueeze(1),\n",
    "#                         y_center[final_conf_mask].unsqueeze(1),\n",
    "#                         w[final_conf_mask].unsqueeze(1),\n",
    "#                         h[final_conf_mask].unsqueeze(1)\n",
    "#                     ], dim=1)\n",
    "#                     pred_boxes_single_image.extend(pred_boxes_batch.tolist())\n",
    "\n",
    "#             nms_boxes = non_max_suppression(pred_boxes_single_image, iou_threshold, confidence_threshold)\n",
    "#             for nms_box in nms_boxes:\n",
    "#                 all_pred_boxes.append([train_idx] + nms_box)\n",
    "#             train_idx += 1\n",
    "            \n",
    "#     model.train()\n",
    "#     return all_pred_boxes\n",
    "\n",
    "# def mean_average_precision(pred_boxes, true_boxes, iou_threshold=0.5, num_classes=11):\n",
    "#     average_precisions = []\n",
    "#     epsilon = 1e-6\n",
    "\n",
    "#     for c in range(num_classes):\n",
    "#         detections = [d for d in pred_boxes if d[1] == c]\n",
    "#         ground_truths = [gt for gt in true_boxes if gt[1] == c]\n",
    "\n",
    "#         amount_bboxes = Counter(gt[0] for gt in ground_truths)\n",
    "#         for key, val in amount_bboxes.items():\n",
    "#             amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "#         detections.sort(key=lambda x: x[2], reverse=True)\n",
    "#         TP = torch.zeros(len(detections))\n",
    "#         FP = torch.zeros(len(detections))\n",
    "#         total_true_bboxes = len(ground_truths)\n",
    "        \n",
    "#         if total_true_bboxes == 0: continue\n",
    "\n",
    "#         for detection_idx, detection in enumerate(detections):\n",
    "#             ground_truth_img = [bbox for bbox in ground_truths if bbox[0] == detection[0]]\n",
    "#             best_iou = 0\n",
    "#             best_gt_idx = -1\n",
    "\n",
    "#             for idx, gt in enumerate(ground_truth_img):\n",
    "#                 iou = iou_boxes(torch.tensor(detection[1:]), torch.tensor(gt[1:]))\n",
    "#                 if iou > best_iou:\n",
    "#                     best_iou = iou\n",
    "#                     best_gt_idx = idx\n",
    "\n",
    "#             if best_iou > iou_threshold:\n",
    "#                 if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "#                     TP[detection_idx] = 1\n",
    "#                     amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "#                 else:\n",
    "#                     FP[detection_idx] = 1\n",
    "#             else:\n",
    "#                 FP[detection_idx] = 1\n",
    "\n",
    "#         TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "#         FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "#         recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "#         precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n",
    "        \n",
    "#         precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "#         recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "#         average_precisions.append(torch.trapz(precisions, recalls))\n",
    "\n",
    "#     return sum(average_precisions) / (len(average_precisions) + epsilon)\n",
    "\n",
    "# def check_accuracy(loader, model, device):\n",
    "#     print(\"\\nCalculating mAP...\")\n",
    "#     model.eval()\n",
    "    \n",
    "#     # Get predictions\n",
    "#     pred_boxes = get_all_bboxes(\n",
    "#         loader, model, \n",
    "#         iou_threshold=IOU_THRESHOLD, \n",
    "#         confidence_threshold=CONFIDENCE_THRESHOLD, \n",
    "#         anchors=ANCHORS, \n",
    "#         device=device\n",
    "#     )\n",
    "    \n",
    "#     # Get ground truths (simplified extraction from dataset)\n",
    "#     true_boxes = []\n",
    "#     for idx in range(len(loader.dataset)):\n",
    "#         _, targets = loader.dataset[idx]\n",
    "#         for scale_idx in range(3):\n",
    "#             anchors_on_scale = targets[scale_idx]\n",
    "#             # Mask where object exists: [3, S, S, 6]\n",
    "#             mask = anchors_on_scale[..., 0] == 1\n",
    "#             if mask.any():\n",
    "#                 # Extract: [class, x, y, w, h]\n",
    "#                 # targets storage: [obj, x, y, w, h, class]\n",
    "#                 valid_targets = anchors_on_scale[mask]\n",
    "#                 for t in valid_targets:\n",
    "#                     # Format for mAP: [train_idx, class, prob(1), x, y, w, h]\n",
    "#                     # GT prob is 1.0\n",
    "#                     true_boxes.append([\n",
    "#                         idx, \n",
    "#                         t[5].item(), \n",
    "#                         1.0, \n",
    "#                         t[1].item(), t[2].item(), t[3].item(), t[4].item()\n",
    "#                     ])\n",
    "\n",
    "#     map_val = mean_average_precision(pred_boxes, true_boxes, iou_threshold=IOU_THRESHOLD, num_classes=NUM_CLASSES)\n",
    "#     print(f\"mAP: {map_val:.4f}\")\n",
    "#     model.train()\n",
    "#     return map_val\n",
    "\n",
    "# def train_model(model, loader, optimizer, criterion, device, scaled_anchors):\n",
    "#     model.train()\n",
    "#     loop = tqdm(loader, leave=True)\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     for imgs, labels in loop:\n",
    "#         imgs = imgs.to(device)\n",
    "#         labels = (\n",
    "#             labels[0].to(device),\n",
    "#             labels[1].to(device),\n",
    "#             labels[2].to(device),\n",
    "#         )\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         preds = model(imgs)\n",
    "        \n",
    "#         # Check for NaN in inputs\n",
    "#         if torch.isnan(imgs).any():\n",
    "#             print(\"Warning: NaN input image detected\")\n",
    "#             continue\n",
    "\n",
    "#         loss = criterion(preds, labels, scaled_anchors)\n",
    "        \n",
    "#         if torch.isnan(loss):\n",
    "#             print(\"Warning: Loss is NaN, skipping step\")\n",
    "#             optimizer.zero_grad()\n",
    "#             continue\n",
    "            \n",
    "#         loss.backward()\n",
    "        \n",
    "#         # FIXED: Gradient Clipping\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        \n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "#         loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "#     avg_loss = total_loss / len(loader)\n",
    "#     print(f\"Average Loss: {avg_loss}\")\n",
    "#     return avg_loss\n",
    "\n",
    "# # --- MAIN BLOCK ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Update these paths to your actual directories\n",
    "#     image_dir = \"/home/abdullah/YOLO_BTP/RadDet_128_1T/RadDet40k128HW001Tv2/images/train\"\n",
    "#     label_dir = \"/home/abdullah/YOLO_BTP/RadDet_128_1T/RadDet40k128HW001Tv2/labels/train\"\n",
    "    \n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(f\"Using device: {device}\")\n",
    "    \n",
    "#     # Scaled anchors for loss calculation \n",
    "#     scaled_anchors = (\n",
    "#         torch.tensor(ANCHORS) / torch.tensor([IMG_SIZE, IMG_SIZE])\n",
    "#     ).to(device)\n",
    "\n",
    "#     dataset = RadarDataset(image_dir, label_dir, anchors=ANCHORS, S=S, C=NUM_CLASSES)\n",
    "#     loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "#     model = YOLOv3(in_channels=1, num_classes=NUM_CLASSES).to(device)\n",
    "    \n",
    "#     # Use a safe epsilon for Adam\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4, eps=1e-6)\n",
    "#     criterion = YoloLoss()\n",
    "    \n",
    "#     # Training Loop\n",
    "#     for epoch in range(EPOCHS):\n",
    "#         print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "#         train_model(model, loader, optimizer, criterion, device, scaled_anchors)\n",
    "        \n",
    "#         # Evaluate every 5 epochs to save time, or every epoch if dataset is small\n",
    "#         if (epoch + 1) % 5 == 0:\n",
    "#              check_accuracy(loader, model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
